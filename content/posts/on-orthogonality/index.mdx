---
title: On Orthogonality
date: 2025-11-30
description: Exploring the concept of orthogonality and its implications for thinking about systems, values, and the structure of possibility spaces.
tags:
  - personal
  - insights
  - mathematics
  - linear-algebra
  - philosophy
---

Work has recently made me think a lot about the concept of 'orthogonality'. I use the idea to revisit the evolution of my personal beliefs from a mathematical standpoint:

1. Understand your blind ~~spots~~ dimensions.
2. Take ~~more~~ different risks
3. Nurture your ~~unique~~ orthogonal gifts

First, what does orthogonality, the state of two vectors being *orthogonal*, mean? Here are some definitions that get increasingly less precise but more intuitive.

Two vectors $u$ and $v$ are orthogonal if...

1. Their inner product is zero: $\langle u, v \rangle = 0$
2. They meet at a right angle
3. They are maximally independent, meaning knowing something about one tells you absolutely nothing about the other ([datcreativity.com](https://www.datcreativity.com))
4. One represents genuinely new information that expands what the space can express with the other

## 1. Understand your blind ~~spots~~ dimensions.

> The little quail laughs at him, saying, "Where does he think he's going? I give a great leap and fly up, but I never get more than ten or twelve yards before I come down fluttering among the weeds and brambles. And that's the best kind of flying, anyway! Where does he think he's going?" Such is the difference between big and little.
> - Zhuangzi

How would you model the collection of your thoughts?

The most natural model to me feels like a high dimensional space, where each point represents a single thought. In a similar way to how embeddings like [CLIP](https://openai.com/index/clip/) represent abstract dimensions, I don't know what these dimensions intuitively 'mean' or are, but since we all eat and poop, I imagine some dimensions are highly correlated with those concepts.

![High-dimensional thought space visualization showing points representing individual thoughts in a multi-dimensional space](/orthogonality-thought-space.svg)

Ok, so then, how does communication work? One observation is we know communication happens, so our thoughts must have a pretty good low rank approximation, i.e. they can be projected down to a shared dimension without losing too much information.

![Low rank approximation visualization showing projection from high-dimensional space to shared communication dimension](/orthogonality-communication-projection.svg)

But what about moments of major miscommunication? When we bicker with loved ones about the intentions of our words? Or when a teacher has explained something to you that completely went over your head? These to me are like noisy projections or projections onto a rotated basis. That's why we can partially understand each other while missing nuances, or the orthogonal components in each of our thoughts.

![Visualization of argument with two orthogonal components clashing, showing miscommunication as rotated basis projection](/orthogonality-miscommunication.svg)

What orthogonality highlights, though, is that the nuance we miss, the orthogonal component the projection doesn't capture, is that it's not a blind spot. It's not a part of your car you can't see when you're backing out. It's a whole dimension. The above passage from Zhuangzi makes me think of this idea powerfully. For a quail, it doesn't understand the Peng that is flying for thousands of kilometres in the sky. There are things that completely fly past our heads. To a consciousness confined to a subspace, an orthogonal vector is invisible.

And once we consider our ignorance not in terms of little patches to uncover, but entire dimensions to discover, it's quite scary. Just to give a taste as to why this scary all sorts of other reasons, consider the curse of dimensionality. If we assume that our thoughts are roughly uniformly distribute across higher dimensions, the distance between them explodes evenly (interestingly why high-dimensional bootstrap methods fail). This explains why thinking from even a couple more perspectives than what we usually do feels so much more taxing.

The only way to reduce this is to i) feel orthogonal moments, and ii) add a basis vector as a result. In my model so far, this is impossible. But we know this isn't the case. Teachers - titled and not - can guide us to seeing things in ways that we have never seen before. After all, mathematically, discovering new dimensions is trivial—you just need a single example that can't be expressed as a linear combination of your basis vectors. One counterexample immediately proves the new dimension exists. The real problem isn't that orthogonal dimensions are _undetectable_—it's that without encountering them, you have no reason to suspect they exist.

This makes me feel in awe at the complexity, depth and mysticism of the world.

## 2. Take ~~more~~ different risks

First, a quick overview on why independent bets are great. Suppose you have a bet with expected value $\mu$ and variance $\sigma^2$. If you take $n$ independent identical bets, the central limit theorem tells us:

- Your total expected value scales linearly: $n\mu$
- Your total variance scales linearly: $n\sigma^2$
- But your _standard deviation per unit expectation_ scales as $\sqrt{n}$

This means taking more of the same bet gives you $\sqrt{n}$ times better risk-adjusted returns, which is pretty neat.

Now consider taking bets on _uncorrelated_ outcomes. This is where portfolio theory becomes powerful. Let $\mathbf{w} = (w_1, w_2, \ldots, w_n)^T$ be your portfolio weights (where $\sum w_i = 1$), $\mathbf{r} = (r_1, r_2, \ldots, r_n)^T$ be the vector of asset returns, and $\Sigma$ be the covariance matrix where $\Sigma_{ij} = \text{Cov}(r_i, r_j)$.

Portfolio variance becomes: $$\sigma_p^2 = \mathbf{w}^T \Sigma \mathbf{w} = \sum_{i=1}^n \sum_{j=1}^n w_i w_j \sigma_{ij}$$

Expected return is simply: $$\mu_p = \mathbf{w}^T \boldsymbol{\mu}$$

The diagonal terms $w_i^2 \sigma_i^2$ represent each asset's individual risk contribution—these scale with the square of your allocation.

But the off-diagonal terms $2w_i w_j \rho_{ij} \sigma_i \sigma_j$ are where diversification happens. With $n$ assets, you have $n$ diagonal terms but $\frac{n(n-1)}{2}$ off-diagonal terms. As $n$ grows large, the off-diagonal correlations dominate. If correlations are low, adding more assets drives portfolio variance toward zero even while maintaining positive expected returns. You get the numerator (returns) without the denominator (risk).

The critical insight is in the off-diagonal terms: $2w_i w_j \rho_{ij} \sigma_i \sigma_j$. When assets are _orthogonal_ ($\rho = 0$), these terms vanish entirely—you get pure variance reduction with no interference. But when $\rho > 0$, these positive cross-terms _add_ to your total variance, contaminating the diversification benefit.

The mathematical beauty: with $n$ assets, you have $n$ variance terms but $\frac{n(n-1)}{2}$ correlation terms. As $n$ grows, the correlations increasingly dominate the portfolio variance. If those correlations are near zero (orthogonal dimensions), your portfolio variance shrinks as $\frac{\bar{\sigma}^2}{n}$—you get the law of large numbers working for you. But if $\rho$ is high across all pairs, you're essentially holding one asset in $n$ different wrappers.

Orthogonality isn't just helpful—it's the _only_ thing that makes diversification work. Without it, $\mathbf{w}^T \Sigma \mathbf{w}$ doesn't shrink as you add dimensions; it stays stubbornly high because the covariance matrix remains rank-deficient in the effective dimension space.

I apply this idea in my own life by measuring my life's features by tracking six life dimensions fortnightly since 2023, and the data reveals both what I've done right and my biggest remaining vulnerability. The wins: I've successfully reduced my life's volatility—my well-being swings have compressed from 5-point ranges in 2023-24 to ~3.7 points in 2025—by diversifying into fitness (triathlon training), relationships (Fran), and creative work (writing). When my career crashed in fall 2024 (no DESCO offer, identity score plummeted to 2), my learning dimension actually _improved_ to 7-9, proving orthogonality works: uncorrelated bets provide natural hedges. But here's the glaring failure: career still explains 65% of my well-being variance (ρ = 0.81 with overall satisfaction), and Contribution & Impact sits at 1—essentially a neglected asset with near-zero correlation to everything else. The math is screaming at me: investing heavily in contribution ([The Anti-Racism Kit](https://publishing.hardiegrant.com/en-us/books/the-anti-racism-kit-by-jinyoung-kim/9781761211171), the networking dinners, public writing) would provide massive diversification benefits because it's orthogonal to whether Two Sigma is going well or Fran is in town. I've been good at building moderately correlated dimensions (relationship, fitness, creativity all ρ ≈ 0.4-0.6 with career), but I've completely ignored the one dimension that could genuinely stabilize my portfolio. The strategic move isn't to grind harder at work or optimize my relationship further—it's to bring that 1 up to a 6, which would reduce my overall volatility by ~20% while adding a source of meaning that doesn't crash when my performance review disappoints or my deadlift plateaus.

## 3. Nurture your own orthogonal components, others won't

> Come mothers and fathers  
> Throughout the land  
> And don't criticize  
> What you can't understand  
> ...  
> For the times they are a-changin'  
> — Bob Dylan, "The Times They Are A-Changin'"

[Listen to Bob Dylan - The Times They Are A-Changin' (1:47-2:20)](https://open.spotify.com/track/52vA3CYKZqZVdQnzRrdZt6?si=eedf21b068d943e8#t=1:47)

i) You cannot notice them. Really weird things. It's the alien. It's the mysterious. The truly incomprehensible.

ii) But others won't too! So when a little voice in you says something you're saying is valuable, dwell on it. Sometimes it's the ego, confirmation bias, you're wrong. But sometimes it's the special sauce everyone will neglect. Ask yourself questions like what are things I can see that others can't? Where do I see beauty and value where others scoff and laugh? And what do I have a knack at that others don't?

iii) Can't rank orthogonal components face value. Can analyze them with regards to an ultimate goal however. It's like comparing apples and oranges. Contextual notions of usefulness. They're fundamental units in however you want to splice and dice the world.

iv) And a lot of things aren't just unique or not. There are shades to it. So correlation number to the world. But there are lots of things in the world. Max correlation to every other idea, thing, given reference class in the world is cool.

v) But to portfolio optimize the world, we need orthogonal people!

vi) We also need to radically reimagine what 'useful' means. Basically if all of us were AI alignment researchers, the world would lose out on orthogonal components of perspectives, skills, talents. We need artists. We need professions that are not immediately 'useful'. We need those people even where is starvation and hunger, and I think the suffocating rhetoric of usefulness needs to stop.

Listen to your gut. To taste. To developing those qualities that might not be celebrated.
