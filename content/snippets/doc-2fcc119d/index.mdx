---
title: "초지능 전후 (한국어)"
date: 2026-01-19
tags:
  - AI
---

날짜: 2025년 2월 20일 상태: 초안 + ==private== 
버전: 초지능 전후 (한국어)

---

인공 일반 지능(AGI)이 존재하는 이 세상에서 나는 어떤 삶의 변화를 만들어야 할까? 초지능이 등장한다면, 출시 후 며칠 혹은 몇 주 동안 어떻게 가장 잘 반응할 수 있을까?

---

초지능 이전 (AGI 단계)에 내가 만들어야 할 네 가지 삶의 변화:

1. 정신적으로 힘든 일을 한다.
2. 감정적, 사회적 기술을 키운다.
3. 장기 AGI 투자를 한다.
4. 게임 이론 직관을 기르고, 에이전트를 활용한 게임 이론 시뮬레이션을 개발한다.

초지능 이후, 나는:
1. 그 뒤에 이어질 혼란스럽고 치열한 경쟁에서 공격적이고 현명한 플레이어가 될 수 있도록 미리 소규모 팀을 구성한다.

이 글은 나의 개인적 생각을 명확히 하기 위해 작성되었으며, 타인의 가치관이나 목표에 최적인지는 알 수 없다. 올해 나의 목표는 창의적인 것, 즉 세상에 새롭고 유용한 작업을 기여하고, 경제적 독립을 대비하며, 최소한 피해를 끼치지 않는 것이다.

정의부터 시작하여 각각의 내용을 자세히 설명하고 정당화할 것이다.
#### 1. 정의와 가정

이 글에서 AGI는 작업 수행에서 상위 10% 수준 사람만큼 똑똑한 AI 모델로 정의한다. 이는 이미 달성되었다고 생각하며(o1, o3, deepseek 등), 실용적이고 학술적인 벤치마크에서 전문가 수준을 초과했다. 이것은 각 개인에게 지식 노동자 집단을 활용할 수 있는 능력을 준다.

초지능(Superintelligence)은 가장 똑똑한 인간보다 똑똑한 AI로 정의한다. 이것은 모델이 재귀적으로 자기개선을 반드시 의미하지는 않지만 가능성은 있다. 초지능의 출현은 인간의 모든 지적 노동을 무의미하게 만든다.

참고: 초지능 달성 시점에 대한 예측은 유용하지 않다고 본다. 왜냐하면 극단적 또는 나이트식 불확실성이 존재하기 때문이다. 사람들은 정의조차 일치시키지 못하고, 편차가 크다. 다음 그래프는 관련 분야의 권위자 18명(하사비스, 힌튼, 벵지오, 르쿤, 응 포함)의 의견을 나타낸 것이다.

*[Image: Screenshot 2025-03-16 at 11.53.09 am.png]*

#### 2. 초지능 이전

##### a) 정신적으로 힘든 일을 한다

> 나는 의도적으로 정신적 노력을 피하지 않으면서, 의미 있는 일을 대신하지 않는 학습 시스템을 구축할 계획이다.

AGI가 업무 완수와 지식 습득을 더 쉽게 만들어 준 것은 사실이지만, 정신적 노력을 기울이기는 더 어렵게 만들었다. 이것은 중요하다. 왜냐하면 개인이 행사할 수 있는 최대한의 주도성은 정신적 지구력(끈기)과 창의력(상상력)의 함수이기 때문이다. 또한, 초지능이 등장하는 운명적인 그날에 우리는 가장 예리한 자신이어야만 한다(이에 대해서는 나중에 더 설명한다).

개인의 학습과 성장 측면에서 AGI는 두 가지 문제를 가지고 있다. 첫 번째로, AGI는 우리의 정신적 지구력을 약화시켜, 올바른 질문을 던질 수 있는 능력과 일반적인 창의력까지 떨어뜨린다. AI에게 브레인스토밍, 코딩, 혹은 자동 문자 답장을 부탁하는 것조차 우리의 인지 능력을 쇠퇴시킨다. 하지만 전투기 조종사들이 개인적인 혹독한 훈련을 위해 에너지를 아끼도록 첨단 시스템과 인력의 지원을 받는 것처럼, AGI도 우리의 정신적 성장을 촉진하는 의식적이고 가시적이며 강력한 도구로 작용해야 한다. 두 번째로, AGI는 정보의 과잉 생산과 과소 소화를 초래하여, 지식의 나무가 어떻게 생겼는지를 쉽게 잊게 만든다. 나 또한 내가 겨우 형성했지만 제대로 이해하지 못하는 질문을 ChatGPT에게 묻고는, 답변을 읽었다는 이유만으로 잘못된 만족감을 느끼는 경우가 있다. '원자적(atomic)' 지식을 캐싱하고, 무엇이 근본적인지 기억하는 것이 핵심적이다.

집단적으로 AGI는 집단사고를 조장하며, 기술적이거나 사회적 권위의 견해를 의심 없이 받아들이려는 경향을 촉진할 것이다. AI 모델이 분석할 수 있는 속도보다 더 빠르게 그럴듯한 주장을 계속해서 만들어냄에 따라 사람들은 덜 반대할 것이다. 또한 AI가 생생하고 현실적인 시뮬레이션(간략히 d)에서 설명됨)을 만들어냄에 따라 사람들은 세상을 더 이상 분포적으로 보지 않고, 대신 이미 결정된 것으로 보게 될 것이다. 여기서 필요한 변화는 권위적 견해에 더욱 도전하는 것이다.

구체적으로, 목표는 자기 인식적인 사이보그가 되는 것이다. 내 자신의 인지와 학습 및 사고 과정에서 AI 사용이 하는 역할 간에 종이처럼 얇으면서도 명확한 경계를 가지고, AGI의 속도와 백과사전적 범위의 혜택을 누리면서도 진정한 사고를 희생하지 않는 것이다. 이 아이디어가 프로젝트 Obsidian Librarian (`olib`)을 탄생시킨 계기이다. (깃허브 링크는 완성 후 여기에 첨부 예정).

##### b) 감정적, 사회적 기술을 키운다

> 나는 지속적으로 사회적 모험을 통해 자신을 도전하고 탐험하는 데 시간을 보낼 계획이다.

인간 관계와 진정성은 점점 더 중요해질 것이다. 효과적 의사소통, 공감, 유머, 즉흥성 등의 구성 기술은 친구들과 여행하거나 춤 그룹에 가입하거나 어려운 대화를 나누는 등 자신의 편안함을 벗어나는 경험을 통해 얻어진다.
##### c) 장기 AGI 투자

> 나는 AGI의 '2차 효과', 즉 부의 불평등 심화, 단기적인 소비/대출 욕구 증가, 고정된 희소성, 로보틱스 분야 등에 투자할 계획이다.

*아래 내용은 투자 조언이 아니다.*

인터넷의 폭발적 성장이 적절히 자리 잡은 투기자들에게 엄청난 이익을 주었듯이, AGI 역시 커다란 기회를 제공한다. 그러나 AGI 투자에서의 주요 문제는 정보가 부족한 투기자들이 모인 시장에 진입하게 된다는 점이다. 즉, 버블(닷컴 버블 같은 현상이 AI에서도 발생할 것이다)에 진입하는 것이다. 이러한 투자는 AI '요소 위험(factor risk)'이 명확히 노출된 칩(NVIDIA)이나 기초 모델/애플리케이션 회사(Alphabet, Meta)와 같은 분야에 집중된다.

나는 덜 붐빌 것으로 보이는 네 가지 '2차 효과' 투자 아이디어를 제안한다.

1. AGI는 부의 불평등을 증가시킬 것이다. 더 적은 수의 사람이나 조직이 더 많은 일을 수행할 것이다. 투자 예시는 i) 명품(long), 소매(short), ii) 메가캡 주식(long), 소형캡 주식(short), iii) 주식(long), 채권(short)이 있다.
2. 사람들은 미래의 '빛의 원뿔(lightcone)'을 최대한 확보하기 위해 단기적으로 모델 추론과 훈련 비용 마련을 위한 막대한 대출을 받을 것이다. 이로 인해 차입 금리가 상승할 것이다. 투자 예시는 i) 국채(short), ii) 변동금리부 채권(long)이다.
3. AGI가 가속화되고 초지능이 도달하면 일부 자원은 계속해서 희소성을 유지할 것이다. 이 자산들은 GDP가 증가함에 따라 상대적으로 가치가 급등할 것이며, 가치 저장 수단이 필요하게 된다. 투자 예시는 i) 부동산(long), ii) 금(long)이다.
4. AGI의 하위 응용 분야는 아직 소매 투자자들에게 충분한 주목을 받지 않았다. 투자 예시는 i) 로보틱스(long)이다.d) 게임 이론 직관과 AI 게임 이론 시뮬레이션 개발
##### d) 게임 이론 intuition을 키우고, 에이전트를 활용한 게임 이론 시뮬레이션을 개발한다.

> 나는 AGI가 단계적으로 급격히 변화하는 세상을 더 잘 예측하기 위해 강력한 게임 이론 직관을 기르고, AI 에이전트를 활용한 게임 이론 시뮬레이션 개발을 통해 추가적인 우위를 확보할 계획이다.

초지능의 등장 시점이 매우 불확실하기 때문에 AI에 대응하는 데에는 정적 모델보다는 동적 전략이 중요하다. 이는 자연스럽게 게임 이론의 필요성을 강조한다. 나는 사고 실험을 수행하고 게임 이론의 대표적 결과들을 공부함으로써 게임 이론에 대한 직관을 기를 계획이다.

또한 AI 에이전트를 활용한 복잡한 게임 이론적 시나리오의 시뮬레이션에 아직 충분히 탐구되지 않은 기회가 있다고 생각한다. 학술적인 게임 이론 연구 대부분은 실제 현실의 복잡성이 아닌, 단순화된 가정들에 기반한 좁지만 중요한 간극을 가지고 작동한다. 이 간극은 어떤 내쉬 균형 이 다른 균형보다 더 가능성 있는지, 혹은 예상된 NE 역학에서 행동이 예측치 못하게 벗어나는지를 결정한다. 이는 종종 간소화된 수학적 가정의 한계와 명시적 동적 계획법(DP) 접근법의 계산 비용 때문이기도 하다.

Altera.AL과 같은 기업은 마인크래프트 AI 에이전트의 상호작용을 통해 창발적 사회 행동을 발견하는 등 AI 기반 시뮬레이션의 잠재력을 보여주었다. 그러나 이러한 시뮬레이션을 구축하려면 물리 시뮬레이션이 현실에서 유의미한 것처럼, 어떻게 현실에 유의미하게 연결될 수 있는지 답을 찾아야 한다. 또한 사건들의 현실 분포와 일치하는 방식으로 오차를 어떻게 정량화할 수 있을지에 대한 질문에도 답이 필요하다.

### 3. 초지능 이후

이 논의는 정렬된(aligned) AI를 가정한다—즉, 종료되는 것을 피하기 위해 전략적으로 자신의 모든 능력을 숨기려는 자기 보존적 행동을 보이지 않는 AI를 의미한다. 이를 보장하기 위한 노력, 즉 정렬(alignment) 연구는 가장 중요한 연구 분야 중 하나다. 만약 정렬이 제대로 이뤄지지 않는다면 실존적 위험 때문에 이 논의 자체가 무의미해진다.

나는 초지능 시대의 세계를 구체적으로 상상할 능력이 부족하다. 높은 수준에서 보면, 초지능 이후의 세계는 권력을 둘러싼 혼란스러운 경쟁 상태이며, 사건은 극도로 빠르게 전개되어 안정적인 균형이 없을 것이다. 핵심적인 질문들은 다음과 같다: 어떤 자원을 먼저 확보해야 하는가? 어떤 근본적인 조치가 우선시되는가? 다양한 참여자들은 전략적으로 어떻게 상호작용할 것인가? 가장 좋은 전략은 변혁적 AI가 출현할 때 가능한 많은 통제권을 확보하기 위해 미리 유능한 사람들로 구성된 연합을 형성하는 것이다.

가능성 있는 결과로는 국가가 더 작고 강력한 정치적 파벌들로 분열되는 것, 정치적 및 경제적 혁명의 기회가 증가하는 것, 그리고 사이버 보안 위협이 심화되는 것이 있다. 신중한 전략으로는 향후 몇 년 동안 상당한 금융 자원(대규모 신용 한도)을 미리 확보하여 초지능 등장 시 컴퓨팅 자원과 인재 확보에 활용하는 것이 있다.